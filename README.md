
# ğŸ§  Voice-Based Cognitive Decline Pattern Detection

This project detects early signs of **cognitive decline** by analyzing speech recordings. It uses **Wav2Vec2** for transcription, extracts **linguistic and acoustic features**, and applies **unsupervised learning** (Isolation Forest & K-Means) to flag individuals potentially at risk. A **Streamlit web app** allows for interactive analysis and visualization.

---

## ğŸš€ Features

- ğŸ”Š Speech-to-text transcription using Facebook's **Wav2Vec2**
- ğŸ§  Cognitive markers from speech (hesitations, speech rate, pitch, semantics)
- ğŸ¤– Unsupervised learning for anomaly & cluster detection
- ğŸ“‰ PCA-based cluster visualization
- ğŸŒ User-friendly Streamlit interface

---

## ğŸ› ï¸ Tech Stack

- Python 3.8+
- Libraries: `transformers`, `torchaudio`, `librosa`, `scikit-learn`, `streamlit`, `pandas`, `matplotlib`, `gensim`
- Model: `facebook/wav2vec2-base-960h` (inference only)

---

## ğŸ“ Project Structure

```
Voice-Based-Cognitive-Decline-Pattern-Detection/
â”‚
â”œâ”€â”€ dataset/                  # Contains audio files (.wav)
â”œâ”€â”€ app.py                   # Streamlit web application
â”œâ”€â”€ model.py                 # Core processing (transcription, features, clustering)
â”œâ”€â”€ README.md                # Project documentation
```

---

## âœ… Setup Instructions

> Make sure you have Python 3.8+ installed.

### 1. Clone the repository

```bash
git clone https://github.com/aishwarya-ag6747/Voice-Based-Cognitive-Decline-Pattern-Detection.git
cd Voice-Based-Cognitive-Decline-Pattern-Detection
```

### 2. Install dependencies

```bash
pip install transformers torchaudio librosa soundfile nltk gensim scikit-learn streamlit matplotlib pandas
```

---

## â–¶ï¸ Running the Web App

```bash
streamlit run app.py
```

Then open the URL shown in the terminal (usually [http://localhost:8501](http://localhost:8501)).

---

## ğŸ“‚ How It Works

1. **Upload** an audio file in `.wav` format.
2. **Transcription** is performed using `Wav2Vec2`.
3. **Features** like hesitations, pitch, rate, and semantics are extracted.
4. **Clustering & anomaly detection** identify speech at risk.
5. **Results** are shown via cluster plot and predicted label.

---

## ğŸ“ Notes

- Works offline; no external API calls.
- Designed for demo/research â€” not clinically validated.
- Wav2Vec2 used for inference only (not fine-tuned).

---

## ğŸ“§ Contact

For queries or contributions:  
**Aishwarya Mondal**  
GitHub: [aishwarya-ag6747](https://github.com/aishwarya-ag6747)

---



